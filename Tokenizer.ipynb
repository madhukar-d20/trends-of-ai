{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a257a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def tokenize_text(text):\n",
    "    \"\"\"\n",
    "    Tokenizes the text and creates a frequency dictionary of tokens.\n",
    "    - Splits by spaces, hyphens, and special characters.\n",
    "    - Treats digits as separate tokens.\n",
    "    - Removes unwanted characters.\n",
    "    \"\"\"\n",
    "    # Create a dictionary to store token frequencies\n",
    "    token_dict = defaultdict(int)\n",
    "\n",
    "    # Define a regular expression that matches words, digits, spaces, periods, and colons\n",
    "    # Everything else is considered a special character and will be skipped\n",
    "    regex = r\"[a-zA-Z]+|\\d+|[ .:]+\"\n",
    "\n",
    "    # Find all matches based on the regex\n",
    "    tokens = re.findall(regex, text)\n",
    "\n",
    "    # Loop through the tokens\n",
    "    for token in tokens:\n",
    "        token.lower()\n",
    "        if token == \" \" or token in {\".\", \":\"}:  # Keep spaces, periods, and colons\n",
    "            token_dict[token] += 1\n",
    "        else:\n",
    "            # If it's a digit, treat each character as a separate token\n",
    "            if token.isdigit():\n",
    "                for digit in token:\n",
    "                    token_dict[digit] += 1\n",
    "            else:\n",
    "                # Otherwise, it's a word, so add it to the dictionary\n",
    "                token_dict[token] += 1\n",
    "\n",
    "    return token_dict\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe01519f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'Hello': 1,\n",
       "             ' ': 8,\n",
       "             'world': 1,\n",
       "             'this': 1,\n",
       "             'is': 1,\n",
       "             '9': 1,\n",
       "             '7': 1,\n",
       "             '2': 2,\n",
       "             'and': 1,\n",
       "             'some': 1,\n",
       "             'more': 1,\n",
       "             'text': 1,\n",
       "             ': ': 1,\n",
       "             '1': 1,\n",
       "             '3': 1,\n",
       "             '.': 1})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "text = \"Hello world, this is, 9 72 and- some-more text: 123.\"\n",
    "token_dict = tokenize_text(text)\n",
    "token_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c407d264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /root/.cache/kagglehub/datasets/zynicide/wine-reviews/versions/4\n",
      "['winemag-data-130k-v2.json', 'winemag-data_first150k.csv', 'winemag-data-130k-v2.csv']\n",
      "Number of rows: 129971\n",
      "Missing values:\n",
      " Unnamed: 0                   0\n",
      "country                     63\n",
      "description                  0\n",
      "designation              37465\n",
      "points                       0\n",
      "price                     8996\n",
      "province                    63\n",
      "region_1                 21247\n",
      "region_2                 79460\n",
      "taster_name              26244\n",
      "taster_twitter_handle    31213\n",
      "title                        0\n",
      "variety                      1\n",
      "winery                       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"zynicide/wine-reviews\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "files = [file for file in os.listdir(path) if os.path.isfile(os.path.join(path, file))]\n",
    "print(files)\n",
    "data = pd.read_csv(f\"{path}/winemag-data-130k-v2.csv\")\n",
    "\n",
    "# all categories\n",
    "#print(data.columns.tolist())\n",
    "\n",
    "print(\"Number of rows:\", data.shape[0])\n",
    "print(\"Missing values:\\n\", data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c19459e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 129971\n",
      "Unnamed: 0               0\n",
      "country                  0\n",
      "description              0\n",
      "designation              0\n",
      "points                   0\n",
      "price                    0\n",
      "province                 0\n",
      "region_1                 0\n",
      "region_2                 0\n",
      "taster_name              0\n",
      "taster_twitter_handle    0\n",
      "title                    0\n",
      "variety                  0\n",
      "winery                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data.fillna(\"\", inplace=True)\n",
    "print(\"Number of rows:\", data.shape[0])\n",
    "\n",
    "missing_values = data.isnull().sum()\n",
    "print(missing_values)\n",
    "data[\"processed_text\"] = (\n",
    "    \"wine review : \" + data[\"country\"].str.strip() + \" : \" + data[\"province\"].str.strip() + \" : \" + data[\"variety\"].str.strip() + \" : \" + data[\"description\"].str.strip()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b88710e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" : \".join(data[\"processed_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28110cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"wine review : Italy : Sicily & Sardinia : White Blend : Aromas include tropical fruit, broom, brimstone and dried herb. The palate isn't overly expressive, offering unripened apple, citrus and dried sage alongside brisk acidity. : wine review : Portugal : Douro : Portuguese Red : This is ripe and fruity, a wine that is smooth while still structured. Firm tannins are filled out with juicy red berry fruits and freshened with acidity. It's  already drinkable, although it will certainly be better from 2016. : wine review : US : Oregon : Pinot Gris : Tart and snappy, the flavors of lime flesh and rind dominate. Some green pineapple pokes through, with crisp acidity underscoring the flavors. The wine was all stainless-steel fermented. : wine review : US : Michigan : Riesling : Pineapple rind, lemon pith and orange blossom start off the aromas. The palate is a bit more opulent, with notes of honey-drizzled guava and mango giving way to a slightly astringent, semidry finish. : wine review : US\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00409ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dd84a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dict = tokenize_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0275ebde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def save_vocab_to_json(token_dict, filename=\"vocab.json\"):\n",
    "    \"\"\"\n",
    "    Saves the vocabulary dictionary to a JSON file.\n",
    "    The format will be:\n",
    "    { 'vocab': [{'token': 'word', 'index': 0, 'count': 5}, ...] }\n",
    "    \"\"\"\n",
    "    # Sort tokens by frequency in descending order\n",
    "    sorted_tokens = sorted(token_dict.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "    # Build the list of vocab entries with token, index, and count\n",
    "    vocab_list = [{'token': token.strip(), 'index': idx, 'count': count} for idx, (token, count) in enumerate(sorted_tokens)]\n",
    "\n",
    "    # Prepare the dictionary to be saved\n",
    "    vocab_json = {'vocab': vocab_list}\n",
    "\n",
    "    # Save to JSON file\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(vocab_json, f, indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1b0a136",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_vocab_to_json(token_dict, \"vocab.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3c8bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (trends_of_ai)",
   "language": "python",
   "name": "trends_of_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
