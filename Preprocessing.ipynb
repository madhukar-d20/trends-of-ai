{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## First dataset and tokenization attempt"
      ],
      "metadata": {
        "id": "pv7w6kdopuoU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XI55CM3toWhj"
      },
      "outputs": [],
      "source": [
        "with open(\"Harry_Potter_all_char_separated.txt\", \"r\") as file:\n",
        "    lines = []\n",
        "    for line in file:\n",
        "        lines = line.split(\"|\")\n",
        "    print(f\"Number of lines :{len(lines)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbzXPIdisxgC",
        "outputId": "a41ad002-18ff-45f6-8cfe-c6c27e36ce0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of characters :6435489\n"
          ]
        }
      ],
      "source": [
        "with open(\"Harry_Potter_all_char_separated.txt\", \"r\") as file:\n",
        "    chars = []\n",
        "    for line in file:\n",
        "        for char in line:\n",
        "            if char != \"|\":\n",
        "                chars.append(char)\n",
        "\n",
        "    print(f\"Number of characters :{len(chars)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "counter = Counter(chars)\n",
        "print(counter)\n",
        "\n",
        "keys = counter.keys()\n",
        "tokens = sorted(list(keys)) #character level tokenization\n",
        "print(f\"Nuber of tokens :{len(tokens)}\\n\")\n",
        "\n",
        "for t in tokens:\n",
        "    print(t, end=\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqkR5Kl5uqG9",
        "outputId": "e4814e8a-97a6-471a-bfab-6c60e48efd93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({' ': 1338782, 'e': 570968, 't': 392008, 'a': 375735, 'o': 366717, 'n': 309034, 'r': 303917, 'i': 296392, 'h': 280449, 's': 278706, 'd': 231033, 'l': 198557, 'u': 138432, 'g': 117841, 'y': 112596, 'w': 107532, 'm': 103770, 'c': 96127, 'f': 90860, ',': 86100, 'p': 73341, 'b': 69118, '.': 62382, 'k': 53744, 'v': 39172, 'H': 38396, '“': 37038, '”': 36415, '’': 34770, 'I': 19208, 'T': 13178, 'S': 11660, 'M': 11096, '?': 10877, 'W': 10263, 'D': 10031, 'R': 9413, 'A': 9244, 'P': 7549, '!': 6943, 'x': 6365, 'B': 6176, 'G': 6098, 'C': 5357, 'N': 4946, 'j': 4860, 'L': 4855, 'Y': 4788, 'F': 4704, 'z': 4468, 'O': 4453, 'E': 4194, 'q': 3495, 'V': 2394, 'U': 2069, 'K': 1824, ':': 1630, 'Q': 822, 'J': 804, '‘': 468, ')': 379, '(': 327, '1': 178, 'Z': 127, 'X': 127, '2': 37, '3': 29, '4': 23, '7': 21, '9': 20, '0': 17, '5': 15, '6': 13, '8': 11, '&': 1})\n",
            "Nuber of tokens :75\n",
            "\n",
            " !&(),.0123456789:?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz‘’“”"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## New Dataset of Wine Reviews and tokenization method"
      ],
      "metadata": {
        "id": "8faKi0zFoQ38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riaUUzPDoP10",
        "outputId": "4c00cc52-411d-4b0d-f40e-66309c402c7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (0.3.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from kagglehub) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"zynicide/wine-reviews\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zT_rEhQ2oP9f",
        "outputId": "fa4f8209-dcb6-4fc3-d2e9-f72aa19c09e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/zynicide/wine-reviews?dataset_version_number=4...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50.9M/50.9M [00:00<00:00, 107MB/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/zynicide/wine-reviews/versions/4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "files = [file for file in os.listdir(path) if os.path.isfile(os.path.join(path, file))]\n",
        "print(files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7vBBWTFqkYe",
        "outputId": "223b98c1-a327-48ce-a404-b5c81bad0ce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['winemag-data-130k-v2.csv', 'winemag-data_first150k.csv', 'winemag-data-130k-v2.json']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(f\"{path}/winemag-data-130k-v2.csv\")\n",
        "\n",
        "# all categories\n",
        "#print(data.columns.tolist())\n",
        "\n",
        "print(\"Number of rows:\", data.shape[0])\n",
        "print(\"Missing values:\\n\", data.isnull().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLFBnXBrrc7B",
        "outputId": "5e4367f0-c05b-4737-c69c-58b4665c4257"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows: 129971\n",
            "Missing values:\n",
            " Unnamed: 0                   0\n",
            "country                     63\n",
            "description                  0\n",
            "designation              37465\n",
            "points                       0\n",
            "price                     8996\n",
            "province                    63\n",
            "region_1                 21247\n",
            "region_2                 79460\n",
            "taster_name              26244\n",
            "taster_twitter_handle    31213\n",
            "title                        0\n",
            "variety                      1\n",
            "winery                       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#remove row with missing values\n",
        "cleaned_data = data.dropna()\n",
        "print(\"Number of rows after cleaning:\", cleaned_data.shape[0])\n",
        "\n",
        "\n",
        "#too less rows after dropping the rows with no data, so decided to fill the missing values insted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcIipPR2tenL",
        "outputId": "fad5ee17-21d4-49c2-bc4f-da2e8d52e23b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows after cleaning: 22387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Filling missing data\n",
        "data.fillna(\"\", inplace=True)\n",
        "print(\"Number of rows:\", data.shape[0])\n",
        "\n",
        "missing_values = data.isnull().sum()\n",
        "print(missing_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DO-NRo8yw_fK",
        "outputId": "04a4f6c8-8578-4e44-dd90-a191c7da71d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-f33e01b52957>:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  data.fillna(\"\", inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows: 129971\n",
            "Unnamed: 0               0\n",
            "country                  0\n",
            "description              0\n",
            "designation              0\n",
            "points                   0\n",
            "price                    0\n",
            "province                 0\n",
            "region_1                 0\n",
            "region_2                 0\n",
            "taster_name              0\n",
            "taster_twitter_handle    0\n",
            "title                    0\n",
            "variety                  0\n",
            "winery                   0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"processed_text\"] = (\n",
        "    \"wine review : \" + data[\"country\"].str.strip() + \" : \" + data[\"province\"].str.strip() + \" : \" + data[\"variety\"].str.strip() + \" : \" + data[\"description\"].str.strip()\n",
        ")\n",
        "\n",
        "\n",
        "print(data[\"processed_text\"].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Khl5JWK-xfsq",
        "outputId": "e2188357-1899-40f5-bac9-f72adb164e9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    wine review : Italy : Sicily & Sardinia : Whit...\n",
            "1    wine review : Portugal : Douro : Portuguese Re...\n",
            "2    wine review : US : Oregon : Pinot Gris : Tart ...\n",
            "3    wine review : US : Michigan : Riesling : Pinea...\n",
            "4    wine review : US : Oregon : Pinot Noir : Much ...\n",
            "Name: processed_text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wdjCWcO0p3a",
        "outputId": "b5ae563d-80a3-4d63-c716-ff97420af055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bert - word pair tokenizer\n",
        "\n",
        "⚠️ Not suitable for text generation, even I dont know why I spent time on this"
      ],
      "metadata": {
        "id": "N0RE0-AVAkPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Tokenize the processed text\n",
        "data[\"tokens\"] = data[\"processed_text\"].apply(lambda x: tokenizer(x, padding=True, truncation=True, max_length=512))\n",
        "\n",
        "# Example: View the first tokenized row\n",
        "print(\"First Tokenized Entry:\")\n",
        "print(data[\"tokens\"].iloc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VAw_9NGyCRK",
        "outputId": "23f98b47-8649-4499-f3c0-618fd735a5ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Tokenized Entry:\n",
            "{'input_ids': [101, 4511, 3319, 1024, 3304, 1024, 12071, 1004, 21594, 1024, 2317, 12586, 1024, 23958, 2015, 2421, 5133, 5909, 1010, 23528, 1010, 7987, 5714, 9221, 1998, 9550, 12810, 1012, 1996, 14412, 3686, 3475, 1005, 1056, 15241, 22570, 1010, 5378, 4895, 29443, 6675, 6207, 1010, 20418, 1998, 9550, 10878, 4077, 28022, 5648, 3012, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = 3\n",
        "processed_text = data[\"processed_text\"].iloc[index]\n",
        "input_ids = data[\"tokens\"].iloc[index][\"input_ids\"]\n",
        "decoded_tokens = [tokenizer.decode([id]) for id in input_ids]\n",
        "decoded_text = tokenizer.decode(data[\"tokens\"].iloc[index][\"input_ids\"])\n",
        "\n",
        "\n",
        "# Print the results\n",
        "print(\"Processed Text:\")\n",
        "print(processed_text)\n",
        "print(\"\\nInput IDs:\")\n",
        "print(input_ids)\n",
        "print(\"\\nDecoded Tokens:\")\n",
        "print(decoded_tokens)\n",
        "print(\"\\nDecoded Text:\")\n",
        "print(decoded_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmTnOezOzyNB",
        "outputId": "d27fdd6e-67e6-4891-e65f-c32a004ffd8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed Text:\n",
            "wine review: US : Michigan : Riesling : Pineapple rind, lemon pith and orange blossom start off the aromas. The palate is a bit more opulent, with notes of honey-drizzled guava and mango giving way to a slightly astringent, semidry finish.\n",
            "\n",
            "Input IDs:\n",
            "[101, 4511, 3319, 1024, 2149, 1024, 4174, 1024, 15544, 2229, 2989, 1024, 7222, 23804, 15544, 4859, 1010, 14380, 6770, 2232, 1998, 4589, 20593, 2707, 2125, 1996, 23958, 2015, 1012, 1996, 14412, 3686, 2003, 1037, 2978, 2062, 6728, 27581, 1010, 2007, 3964, 1997, 6861, 1011, 2852, 10993, 29247, 2094, 19739, 12462, 1998, 24792, 3228, 2126, 2000, 1037, 3621, 2004, 18886, 25997, 2102, 1010, 4100, 21190, 3926, 1012, 102]\n",
            "\n",
            "Decoded Tokens:\n",
            "['[CLS]', 'wine', 'review', ':', 'us', ':', 'michigan', ':', 'ri', '##es', '##ling', ':', 'pine', '##apple', 'ri', '##nd', ',', 'lemon', 'pit', '##h', 'and', 'orange', 'blossom', 'start', 'off', 'the', 'aroma', '##s', '.', 'the', 'pal', '##ate', 'is', 'a', 'bit', 'more', 'op', '##ulent', ',', 'with', 'notes', 'of', 'honey', '-', 'dr', '##iz', '##zle', '##d', 'gu', '##ava', 'and', 'mango', 'giving', 'way', 'to', 'a', 'slightly', 'as', '##tri', '##ngen', '##t', ',', 'semi', '##dry', 'finish', '.', '[SEP]']\n",
            "\n",
            "Decoded Text:\n",
            "[CLS] wine review : us : michigan : riesling : pineapple rind, lemon pith and orange blossom start off the aromas. the palate is a bit more opulent, with notes of honey - drizzled guava and mango giving way to a slightly astringent, semidry finish. [SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Flatten all input_ids from your dataset\n",
        "all_input_ids = [id for tokens in data[\"tokens\"] for id in tokens[\"input_ids\"]]\n",
        "\n",
        "# Count token occurrences\n",
        "token_counts = Counter(all_input_ids)\n",
        "\n",
        "# Map token IDs back to text\n",
        "id_to_token = {id: tokenizer.decode([id]) for id in token_counts.keys()}\n",
        "\n",
        "# Create a list of tuples (Token Text, Token ID, Count) and sort by frequency\n",
        "sorted_tokens_by_frequency = sorted(\n",
        "    [(id_to_token[token_id], token_id, count) for token_id, count in token_counts.items()],\n",
        "    key=lambda x: x[2],  # Sort by count (frequency)\n",
        "    reverse=True         # Descending order\n",
        ")\n",
        "\n",
        "print(f\"Total Tokens: {total_tokens}\")\n",
        "print(f\"Unique Tokens: {len(sorted_tokens_by_frequency)}\")\n",
        "print(\"\\nTop 20 Most Frequent Tokens:\")\n",
        "for token_text, token_id, count in sorted_tokens_by_frequency[:20]:\n",
        "    print(f\"Token: {token_text}, Token ID: {token_id}, Count: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrZbh7Ch5Rza",
        "outputId": "a2273878-fb51-456e-aceb-f15dd4e1c94e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Tokens: 9236768\n",
            "Unique Tokens: 16620\n",
            "\n",
            "Top 20 Most Frequent Tokens:\n",
            "Token: :, Token ID: 1024, Count: 521322\n",
            "Token: ,, Token ID: 1010, Count: 441931\n",
            "Token: ., Token ID: 1012, Count: 356241\n",
            "Token: and, Token ID: 1998, Count: 348172\n",
            "Token: the, Token ID: 1996, Count: 221530\n",
            "Token: wine, Token ID: 4511, Count: 212149\n",
            "Token: a, Token ID: 1037, Count: 180002\n",
            "Token: of, Token ID: 1997, Count: 173073\n",
            "Token: review, Token ID: 3319, Count: 129981\n",
            "Token: [CLS], Token ID: 101, Count: 129971\n",
            "Token: [SEP], Token ID: 102, Count: 129971\n",
            "Token: with, Token ID: 2007, Count: 120532\n",
            "Token: this, Token ID: 2023, Count: 114197\n",
            "Token: ##s, Token ID: 2015, Count: 97905\n",
            "Token: is, Token ID: 2003, Count: 96866\n",
            "Token: -, Token ID: 1011, Count: 89615\n",
            "Token: it, Token ID: 2009, Count: 86121\n",
            "Token: ##y, Token ID: 2100, Count: 70794\n",
            "Token: in, Token ID: 1999, Count: 63212\n",
            "Token: flavors, Token ID: 26389, Count: 62812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPT2 - BPE tokenizer"
      ],
      "metadata": {
        "id": "m2z4pShvBw8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "from transformers import GPT2Tokenizer\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token #to fix error with padding\n",
        "\n",
        "\n",
        "# tested max_length of this dataset, should be fine as now row is longer than 512 hence there wont be any truncation\n",
        "# learnt padding is important for GPU - but need help here\n",
        "data[\"tokens\"] = data[\"processed_text\"].apply(\n",
        "    lambda x: tokenizer(x, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        ")"
      ],
      "metadata": {
        "id": "n5vYSkfi8a4l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e644cb55-d1f8-488b-bc45-abd1f868bff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1min 24s, sys: 636 ms, total: 1min 25s\n",
            "Wall time: 1min 35s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = 0\n",
        "\n",
        "processed_text = data[\"processed_text\"].iloc[index]\n",
        "input_ids = data[\"tokens\"].iloc[index][\"input_ids\"].squeeze().tolist()  # Convert to a flat list\n",
        "decoded_tokens = [tokenizer.decode([id]) for id in input_ids]\n",
        "decoded_text = tokenizer.decode(input_ids)\n",
        "\n",
        "print(\"Processed Text:\")\n",
        "print(processed_text)\n",
        "print(\"\\nInput IDs:\")\n",
        "print(input_ids)\n",
        "print(\"\\nDecoded Tokens:\")\n",
        "print(decoded_tokens)\n",
        "print(\"\\nDecoded Text:\")\n",
        "print(decoded_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPOIa3POGvBI",
        "outputId": "4e2f3df0-1d89-45c5-c859-a3fa4f9b6868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed Text:\n",
            "wine review : Italy : Sicily & Sardinia : White Blend : Aromas include tropical fruit, broom, brimstone and dried herb. The palate isn't overly expressive, offering unripened apple, citrus and dried sage alongside brisk acidity.\n",
            "\n",
            "Input IDs:\n",
            "[39002, 2423, 1058, 8031, 1058, 49301, 1222, 46997, 43168, 1058, 2635, 41198, 1058, 317, 398, 292, 2291, 19690, 8234, 11, 47085, 11, 49943, 6440, 290, 16577, 21047, 13, 383, 44100, 2125, 470, 17698, 38084, 11, 6011, 555, 5528, 2945, 17180, 11, 35405, 290, 16577, 35021, 7848, 35984, 7408, 414, 13]\n",
            "\n",
            "Decoded Tokens:\n",
            "['wine', ' review', ' :', ' Italy', ' :', ' Sicily', ' &', ' Sard', 'inia', ' :', ' White', ' Blend', ' :', ' A', 'rom', 'as', ' include', ' tropical', ' fruit', ',', ' broom', ',', ' brim', 'stone', ' and', ' dried', ' herb', '.', ' The', ' palate', ' isn', \"'t\", ' overly', ' expressive', ',', ' offering', ' un', 'rip', 'ened', ' apple', ',', ' citrus', ' and', ' dried', ' sage', ' alongside', ' brisk', ' acid', 'ity', '.']\n",
            "\n",
            "Decoded Text:\n",
            "wine review : Italy : Sicily & Sardinia : White Blend : Aromas include tropical fruit, broom, brimstone and dried herb. The palate isn't overly expressive, offering unripened apple, citrus and dried sage alongside brisk acidity.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking if there are rows more than 512 tokens - Result: No rows exceed 512 tokens. (atleast for this dataset)\n",
        "# don't run this\n",
        "rows_with_long_tokens = []\n",
        "\n",
        "\n",
        "for index, row in data.iterrows():\n",
        "    tokenized = tokenizer(row[\"processed_text\"], truncation=False)\n",
        "    #tokenized = len(tokenized[\"input_ids\"])\n",
        "\n",
        "    if len(tokenized[\"input_ids\"]) > 512:\n",
        "        rows_with_long_tokens.append((index, row[\"processed_text\"], len(tokenized[\"input_ids\"])))\n",
        "\n",
        "# Display rows with more than 512 tokens\n",
        "if rows_with_long_tokens:\n",
        "    long_token_data = pd.DataFrame(rows_with_long_tokens, columns=[\"Index\", \"Processed Text\", \"Token Count\"])\n",
        "else:\n",
        "    print(\"No rows exceed 512 tokens.\")\n",
        "\n",
        "print(\"Maximum Token Count:\", max_length)"
      ],
      "metadata": {
        "id": "XACPrraACO39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 0\n",
        "for index, row in data.iterrows():\n",
        "    split_tokens = data[\"tokens\"].iloc[index][\"input_ids\"].squeeze().tolist()\n",
        "    max_length = max(max_length, len(split_tokens))\n",
        "\n",
        "print(\"Maximum Token Count:\", max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7JK4EXenUNP",
        "outputId": "4679137a-b85f-4fc0-9335-42f5b29419c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum Token Count: 207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Flatten all input_ids from the tokenized data\n",
        "all_input_ids = [\n",
        "    token_id\n",
        "    for tokens in data[\"tokens\"]\n",
        "    for token_id in tokens[\"input_ids\"].squeeze().tolist()\n",
        "]\n",
        "\n",
        "# Count token occurrences\n",
        "token_counts = Counter(all_input_ids)\n",
        "\n",
        "# Map token IDs back to text\n",
        "id_to_token = {token_id: tokenizer.decode([token_id]) for token_id in token_counts.keys()}\n",
        "\n",
        "# Create a list of tuples (Token Text, Token ID, Count) and sort by frequency\n",
        "sorted_tokens_by_frequency = sorted(\n",
        "    [(id_to_token[token_id], token_id, count) for token_id, count in token_counts.items()],\n",
        "    key=lambda x: x[2],  # Sort by count (frequency)\n",
        "    reverse=True         # Descending order\n",
        ")\n",
        "\n",
        "# Convert to DataFrame for visualization\n",
        "max_rows = 50\n",
        "top_tokens = pd.DataFrame(sorted_tokens_by_frequency[:max_rows], columns=[\"Token Text\", \"Token ID\", \"Count\"])\n",
        "\n",
        "# Display summary\n",
        "total_tokens = sum(token_counts.values())\n",
        "print(f\"Total Tokens: {total_tokens}\")\n",
        "print(f\"Unique Tokens: {len(sorted_tokens_by_frequency)}\")\n",
        "print(f\"\\nTop {max_rows} Most Frequent Tokens:\")\n",
        "print(top_tokens)\n",
        "\n",
        "# limit token to 10k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMoqapnwDp_w",
        "outputId": "cb4a196b-b728-4e8c-dcd6-a789ea037aaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Tokens: 9044969\n",
            "Unique Tokens: 23051\n",
            "\n",
            "Top 50 Most Frequent Tokens:\n",
            "     Token Text  Token ID   Count\n",
            "0             :      1058  519886\n",
            "1             ,        11  440537\n",
            "2             .        13  355484\n",
            "3           and       290  347182\n",
            "4            of       286  172870\n",
            "5           the       262  168174\n",
            "6             a       257  157732\n",
            "7          wine     39002  130064\n",
            "8        review      2423  129979\n",
            "9          with       351  115651\n",
            "10           is       318   96695\n",
            "11            -        12   89417\n",
            "12         wine      8237   80093\n",
            "13         this       428   72883\n",
            "14           to       284   61426\n",
            "15           in       287   60612\n",
            "16      flavors     17361   60316\n",
            "17           US      1294   54506\n",
            "18          The       383   52648\n",
            "19           's       338   51481\n",
            "20        fruit      8234   48682\n",
            "21          ity       414   44576\n",
            "22            t       256   44541\n",
            "23           It       632   43595\n",
            "24           on       319   43095\n",
            "25        black      2042   42748\n",
            "26           it       340   42330\n",
            "27           as       292   41122\n",
            "28         This       770   41122\n",
            "29          ann      1236   40026\n",
            "30         that       326   39400\n",
            "31       palate     44100   38425\n",
            "32   California      3442   37233\n",
            "33         arom     19731   36303\n",
            "34         acid      7408   35574\n",
            "35       finish      5461   34970\n",
            "36          ins      1040   31835\n",
            "37          but       475   31568\n",
            "38            y        88   31257\n",
            "39         from       422   29959\n",
            "40           on       261   29476\n",
            "41           ot       313   27945\n",
            "42       cherry     23612   27563\n",
            "43            A       317   27457\n",
            "44            v        85   26238\n",
            "45          are       389   25834\n",
            "46        Blend     41198   25517\n",
            "47         ripe     29036   25152\n",
            "48        Italy      8031   25073\n",
            "49          has       468   24551\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data[\"tokens\"].iloc[0])"
      ],
      "metadata": {
        "id": "sznJRz3eI8et",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "366f0e18-168e-47d9-c17a-94f43360b2b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[39002,  2423,    25,  8031,  1058, 49301,  1222, 46997, 43168,  1058,\n",
            "          2635, 41198,  1058,   317,   398,   292,  2291, 19690,  8234,    11,\n",
            "         47085,    11, 49943,  6440,   290, 16577, 21047,    13,   383, 44100,\n",
            "          2125,   470, 17698, 38084,    11,  6011,   555,  5528,  2945, 17180,\n",
            "            11, 35405,   290, 16577, 35021,  7848, 35984,  7408,   414,    13]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving tokens to excel"
      ],
      "metadata": {
        "id": "bXhtejJ7ZiMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming data[\"tokens\"] and tokenizer are defined, reinitialize token counting\n",
        "all_input_ids = [\n",
        "    token_id\n",
        "    for tokens in data[\"tokens\"]\n",
        "    for token_id in tokens[\"input_ids\"].squeeze().tolist()\n",
        "]\n",
        "\n",
        "# Count token occurrences\n",
        "token_counts = Counter(all_input_ids)\n",
        "\n",
        "# Map token IDs back to text\n",
        "id_to_token = {token_id: tokenizer.decode([token_id]) for token_id in token_counts.keys()}\n",
        "\n",
        "# Create a sorted list of tokens by frequency\n",
        "sorted_tokens_by_frequency = sorted(\n",
        "    [(id_to_token[token_id], token_id, count) for token_id, count in token_counts.items()],\n",
        "    key=lambda x: x[2],  # Sort by count (frequency)\n",
        "    reverse=True         # Descending order\n",
        ")\n",
        "\n",
        "# Create a DataFrame for all tokens\n",
        "all_tokens_df = pd.DataFrame(sorted_tokens_by_frequency, columns=[\"Token Text\", \"Token ID\", \"Count\"])\n",
        "\n",
        "# Save to Excel\n",
        "file_path = \"all_token_statistics.xlsx\"\n",
        "all_tokens_df.to_excel(file_path, index=False)\n",
        "\n",
        "print(f\"Token statistics for all tokens saved to {file_path}.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wt_X1xySVxXN",
        "outputId": "9a8a1cb3-accd-4626-88c0-3b6902ac1e53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token statistics for all tokens saved to all_token_statistics.xlsx.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hX51vx2cWP_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making one class"
      ],
      "metadata": {
        "id": "WCoFPqNfpyc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub"
      ],
      "metadata": {
        "id": "JrQVtiJxp1dO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import os\n",
        "import pandas as pd\n",
        "from transformers import GPT2Tokenizer\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "1EGL1mrHp2eW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WineReviewProcessor:\n",
        "    def __init__(self, dataset_name=\"zynicide/wine-reviews\"):\n",
        "        self.dataset_name = dataset_name\n",
        "        self.path = kagglehub.dataset_download(self.dataset_name)\n",
        "        print(\"Path to dataset files:\", self.path)\n",
        "        self.files = [file for file in os.listdir(self.path) if os.path.isfile(os.path.join(self.path, file))]\n",
        "        print(\"Dataset files:\", self.files)\n",
        "        self.data = pd.read_csv(f\"{self.path}/winemag-data-130k-v2.csv\")\n",
        "        self.data.fillna(\"\", inplace=True)\n",
        "        print(\"Missing values:\", self.data.isnull().sum())\n",
        "        print(\"Number of rows:\", self.data.shape[0])\n",
        "\n",
        "        self.tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "        self.data[\"processed_text\"] = self._process_text()\n",
        "        self.data[\"tokens\"] = self._tokenize_text()\n",
        "\n",
        "    def _process_text(self):\n",
        "        return (\n",
        "            \"wine review : \" +\n",
        "            self.data[\"country\"].str.strip() + \" : \" +\n",
        "            self.data[\"province\"].str.strip() + \" : \" +\n",
        "            self.data[\"variety\"].str.strip() + \" : \" +\n",
        "            self.data[\"description\"].str.strip()\n",
        "        )\n",
        "\n",
        "    def _tokenize_text(self):\n",
        "        return self.data[\"processed_text\"].apply(\n",
        "            lambda x: self.tokenizer(\n",
        "                x,\n",
        "                padding=True,\n",
        "                truncation=True,\n",
        "                max_length=512,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def get_tokenized_data(self, index):\n",
        "        processed_text = self.data[\"processed_text\"].iloc[index]\n",
        "        input_ids = self.data[\"tokens\"].iloc[index][\"input_ids\"].squeeze().tolist()\n",
        "        decoded_tokens = [self.tokenizer.decode([id]) for id in input_ids]\n",
        "        decoded_text = self.tokenizer.decode(input_ids)\n",
        "\n",
        "        return {\n",
        "            \"processed_text\": processed_text,\n",
        "            \"input_ids\": input_ids,\n",
        "            \"decoded_tokens\": decoded_tokens,\n",
        "            \"decoded_text\": decoded_text\n",
        "        }\n",
        "\n",
        "    def get_max_token_length(self):\n",
        "        max_length = 0\n",
        "        for tokens in self.data[\"tokens\"]:\n",
        "            split_tokens = tokens[\"input_ids\"].squeeze().tolist()\n",
        "            max_length = max(max_length, len(split_tokens))\n",
        "        return max_length\n",
        "\n",
        "    def analyze_tokens(self, max_rows=50):\n",
        "        all_input_ids = []\n",
        "\n",
        "    # Collect all token IDs into a flat list\n",
        "        for tokens in self.data[\"tokens\"]:\n",
        "            input_ids = tokens[\"input_ids\"]\n",
        "            if isinstance(input_ids[0], list):  # Handle list of lists\n",
        "                all_input_ids.extend([token_id for sublist in input_ids for token_id in sublist])\n",
        "            else:  # Handle flat list\n",
        "                all_input_ids.extend(input_ids)\n",
        "\n",
        "    # Count frequencies of token IDs\n",
        "        token_counts = Counter(all_input_ids)\n",
        "\n",
        "    # Map token IDs to their decoded texts\n",
        "        id_to_token = {token_id: self.tokenizer.decode([token_id]) for token_id in token_counts.keys()}\n",
        "        sorted_tokens_by_frequency = sorted(\n",
        "            [(id_to_token[token_id], token_id, count) for token_id, count in token_counts.items()],\n",
        "            key=lambda x: x[2],\n",
        "            reverse=True,\n",
        "        )\n",
        "\n",
        "    # Prepare a DataFrame for the top tokens\n",
        "        top_tokens = pd.DataFrame(sorted_tokens_by_frequency[:max_rows], columns=[\"Token Text\", \"Token ID\", \"Count\"])\n",
        "\n",
        "        total_tokens = sum(token_counts.values())\n",
        "        unique_tokens = len(token_counts)\n",
        "\n",
        "        return {\n",
        "            \"total_tokens\": total_tokens,\n",
        "            \"unique_tokens\": unique_tokens,\n",
        "            \"top_tokens\": top_tokens,\n",
        "        }\n",
        "\n",
        "    def limit_tokens(self, max_tokens=10000):\n",
        "        all_input_ids = [\n",
        "            token_id\n",
        "            for tokens in self.data[\"tokens\"]\n",
        "            for token_id in tokens[\"input_ids\"].squeeze().tolist()\n",
        "        ]\n",
        "\n",
        "        token_counts = Counter(all_input_ids)\n",
        "        sorted_tokens = sorted(token_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "        top_tokens = {token_id for token_id, _ in sorted_tokens[:max_tokens]}\n",
        "\n",
        "        def filter_tokens(tokenized_row):\n",
        "            filtered_input_ids = [\n",
        "                token_id\n",
        "                for token_id in tokenized_row[\"input_ids\"].squeeze().tolist()\n",
        "                if token_id in top_tokens\n",
        "            ]\n",
        "            tokenized_row[\"input_ids\"] = [[token_id] for token_id in filtered_input_ids]\n",
        "            return tokenized_row\n",
        "\n",
        "        self.data[\"tokens\"] = self.data[\"tokens\"].apply(filter_tokens)\n",
        "\n",
        "    def get_data_for_training(self):\n",
        "        return self.data\n"
      ],
      "metadata": {
        "id": "KnLwLJRQp5mv"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "processor = WineReviewProcessor()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AKEUM7lp6VP",
        "outputId": "4347e2ae-9e7c-45c9-e13e-043791ddfe65"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/zynicide/wine-reviews/versions/4\n",
            "Dataset files: ['winemag-data-130k-v2.csv', 'winemag-data_first150k.csv', 'winemag-data-130k-v2.json']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-071bb989874f>:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  self.data.fillna(\"\", inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values: Unnamed: 0               0\n",
            "country                  0\n",
            "description              0\n",
            "designation              0\n",
            "points                   0\n",
            "price                    0\n",
            "province                 0\n",
            "region_1                 0\n",
            "region_2                 0\n",
            "taster_name              0\n",
            "taster_twitter_handle    0\n",
            "title                    0\n",
            "variety                  0\n",
            "winery                   0\n",
            "dtype: int64\n",
            "Number of rows: 129971\n",
            "CPU times: user 1min 56s, sys: 558 ms, total: 1min 57s\n",
            "Wall time: 2min 3s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get tokenized data for a specific index\n",
        "data_summary = processor.get_tokenized_data(index=0)\n",
        "print(\"Processed Text:\", data_summary[\"processed_text\"])\n",
        "print(\"Input IDs:\", data_summary[\"input_ids\"])\n",
        "print(\"Decoded Tokens:\", data_summary[\"decoded_tokens\"])\n",
        "print(\"Decoded Text:\", data_summary[\"decoded_text\"])"
      ],
      "metadata": {
        "id": "vXtUGc4EqI7q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "f818c94d-f79b-415f-c220-5f1d6f7a6ef9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'squeeze'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-442c979c7cfc>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get tokenized data for a specific index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tokenized_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Processed Text:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_summary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"processed_text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input IDs:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_summary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Decoded Tokens:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_summary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"decoded_tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-071bb989874f>\u001b[0m in \u001b[0;36mget_tokenized_data\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_tokenized_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mprocessed_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"processed_text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mdecoded_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mdecoded_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'squeeze'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Maximum token length\n",
        "max_token_length = processor.get_max_token_length()\n",
        "print(\"Maximum Token Count:\", max_token_length)"
      ],
      "metadata": {
        "id": "hqAedEnvqKaT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8481d2f-e6cb-4930-c751-0b15a70b7c96"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum Token Count: 207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze tokens\n",
        "token_analysis = processor.analyze_tokens()\n",
        "print(f\"Total Tokens: {token_analysis['total_tokens']}\")\n",
        "print(f\"Unique Tokens: {token_analysis['unique_tokens']}\")\n",
        "#print(f\"Top Tokens:\\n{token_analysis['top_tokens']}\")"
      ],
      "metadata": {
        "id": "3nsUmprhqMpF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "e656e786-2475-45ef-bbc1-e4b5d49f007c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "int() argument must be a string, a bytes-like object or a real number, not 'list'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-4f0407563277>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Analyze tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtoken_analysis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Total Tokens: {token_analysis['total_tokens']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unique Tokens: {token_analysis['unique_tokens']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#print(f\"Top Tokens:\\n{token_analysis['top_tokens']}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-071bb989874f>\u001b[0m in \u001b[0;36manalyze_tokens\u001b[0;34m(self, max_rows)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m# Map token IDs to their decoded texts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mid_to_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtoken_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoken_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         sorted_tokens_by_frequency = sorted(\n\u001b[1;32m     76\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_to_token\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoken_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-071bb989874f>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m# Map token IDs to their decoded texts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mid_to_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtoken_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoken_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         sorted_tokens_by_frequency = sorted(\n\u001b[1;32m     76\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_to_token\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoken_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3841\u001b[0m         \u001b[0mtoken_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_py_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3843\u001b[0;31m         return self._decode(\n\u001b[0m\u001b[1;32m   3844\u001b[0m             \u001b[0mtoken_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3845\u001b[0m             \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, spaces_between_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decode_use_source_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"use_source_tokenizer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m         \u001b[0mfiltered_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_ids_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m         \u001b[0;31m# If given is a single id, prevents splitting the string in upcoming loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mconvert_ids_to_tokens\u001b[0;34m(self, ids, skip_special_tokens)\u001b[0m\n\u001b[1;32m   1064\u001b[0m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1067\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mskip_special_tokens\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_special_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a real number, not 'list'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processor.limit_tokens()"
      ],
      "metadata": {
        "id": "BLiPGAhoY5A6"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze tokens\n",
        "token_analysis = processor.analyze_tokens()\n",
        "print(f\"Total Tokens: {token_analysis['total_tokens']}\")\n",
        "print(f\"Unique Tokens: {token_analysis['unique_tokens']}\")"
      ],
      "metadata": {
        "id": "zvAEEFiDZxj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processor.get_data_for_training()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "p2BPr3lNY-7v",
        "outputId": "7c0036cb-9715-463f-d5c3-dfef0e42a9c7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Unnamed: 0   country  \\\n",
              "0                0     Italy   \n",
              "1                1  Portugal   \n",
              "2                2        US   \n",
              "3                3        US   \n",
              "4                4        US   \n",
              "...            ...       ...   \n",
              "129966      129966   Germany   \n",
              "129967      129967        US   \n",
              "129968      129968    France   \n",
              "129969      129969    France   \n",
              "129970      129970    France   \n",
              "\n",
              "                                              description  \\\n",
              "0       Aromas include tropical fruit, broom, brimston...   \n",
              "1       This is ripe and fruity, a wine that is smooth...   \n",
              "2       Tart and snappy, the flavors of lime flesh and...   \n",
              "3       Pineapple rind, lemon pith and orange blossom ...   \n",
              "4       Much like the regular bottling from 2012, this...   \n",
              "...                                                   ...   \n",
              "129966  Notes of honeysuckle and cantaloupe sweeten th...   \n",
              "129967  Citation is given as much as a decade of bottl...   \n",
              "129968  Well-drained gravel soil gives this wine its c...   \n",
              "129969  A dry style of Pinot Gris, this is crisp with ...   \n",
              "129970  Big, rich and off-dry, this is powered by inte...   \n",
              "\n",
              "                                   designation  points price  \\\n",
              "0                                 Vulkà Bianco      87         \n",
              "1                                     Avidagos      87  15.0   \n",
              "2                                                   87  14.0   \n",
              "3                         Reserve Late Harvest      87  13.0   \n",
              "4           Vintner's Reserve Wild Child Block      87  65.0   \n",
              "...                                        ...     ...   ...   \n",
              "129966  Brauneberger Juffer-Sonnenuhr Spätlese      90  28.0   \n",
              "129967                                              90  75.0   \n",
              "129968                                   Kritt      90  30.0   \n",
              "129969                                              90  32.0   \n",
              "129970           Lieu-dit Harth Cuvée Caroline      90  21.0   \n",
              "\n",
              "                 province             region_1           region_2  \\\n",
              "0       Sicily & Sardinia                 Etna                      \n",
              "1                   Douro                                           \n",
              "2                  Oregon    Willamette Valley  Willamette Valley   \n",
              "3                Michigan  Lake Michigan Shore                      \n",
              "4                  Oregon    Willamette Valley  Willamette Valley   \n",
              "...                   ...                  ...                ...   \n",
              "129966              Mosel                                           \n",
              "129967             Oregon               Oregon       Oregon Other   \n",
              "129968             Alsace               Alsace                      \n",
              "129969             Alsace               Alsace                      \n",
              "129970             Alsace               Alsace                      \n",
              "\n",
              "               taster_name taster_twitter_handle  \\\n",
              "0            Kerin O’Keefe          @kerinokeefe   \n",
              "1               Roger Voss            @vossroger   \n",
              "2             Paul Gregutt           @paulgwine    \n",
              "3       Alexander Peartree                         \n",
              "4             Paul Gregutt           @paulgwine    \n",
              "...                    ...                   ...   \n",
              "129966  Anna Lee C. Iijima                         \n",
              "129967        Paul Gregutt           @paulgwine    \n",
              "129968          Roger Voss            @vossroger   \n",
              "129969          Roger Voss            @vossroger   \n",
              "129970          Roger Voss            @vossroger   \n",
              "\n",
              "                                                    title         variety  \\\n",
              "0                       Nicosia 2013 Vulkà Bianco  (Etna)     White Blend   \n",
              "1           Quinta dos Avidagos 2011 Avidagos Red (Douro)  Portuguese Red   \n",
              "2           Rainstorm 2013 Pinot Gris (Willamette Valley)      Pinot Gris   \n",
              "3       St. Julian 2013 Reserve Late Harvest Riesling ...        Riesling   \n",
              "4       Sweet Cheeks 2012 Vintner's Reserve Wild Child...      Pinot Noir   \n",
              "...                                                   ...             ...   \n",
              "129966  Dr. H. Thanisch (Erben Müller-Burggraef) 2013 ...        Riesling   \n",
              "129967                  Citation 2004 Pinot Noir (Oregon)      Pinot Noir   \n",
              "129968  Domaine Gresser 2013 Kritt Gewurztraminer (Als...  Gewürztraminer   \n",
              "129969      Domaine Marcel Deiss 2012 Pinot Gris (Alsace)      Pinot Gris   \n",
              "129970  Domaine Schoffit 2012 Lieu-dit Harth Cuvée Car...  Gewürztraminer   \n",
              "\n",
              "                                          winery  \\\n",
              "0                                        Nicosia   \n",
              "1                            Quinta dos Avidagos   \n",
              "2                                      Rainstorm   \n",
              "3                                     St. Julian   \n",
              "4                                   Sweet Cheeks   \n",
              "...                                          ...   \n",
              "129966  Dr. H. Thanisch (Erben Müller-Burggraef)   \n",
              "129967                                  Citation   \n",
              "129968                           Domaine Gresser   \n",
              "129969                      Domaine Marcel Deiss   \n",
              "129970                          Domaine Schoffit   \n",
              "\n",
              "                                           processed_text  \\\n",
              "0       wine review : Italy : Sicily & Sardinia : Whit...   \n",
              "1       wine review : Portugal : Douro : Portuguese Re...   \n",
              "2       wine review : US : Oregon : Pinot Gris : Tart ...   \n",
              "3       wine review : US : Michigan : Riesling : Pinea...   \n",
              "4       wine review : US : Oregon : Pinot Noir : Much ...   \n",
              "...                                                   ...   \n",
              "129966  wine review : Germany : Mosel : Riesling : Not...   \n",
              "129967  wine review : US : Oregon : Pinot Noir : Citat...   \n",
              "129968  wine review : France : Alsace : Gewürztraminer...   \n",
              "129969  wine review : France : Alsace : Pinot Gris : A...   \n",
              "129970  wine review : France : Alsace : Gewürztraminer...   \n",
              "\n",
              "                             tokens  \n",
              "0       [input_ids, attention_mask]  \n",
              "1       [input_ids, attention_mask]  \n",
              "2       [input_ids, attention_mask]  \n",
              "3       [input_ids, attention_mask]  \n",
              "4       [input_ids, attention_mask]  \n",
              "...                             ...  \n",
              "129966  [input_ids, attention_mask]  \n",
              "129967  [input_ids, attention_mask]  \n",
              "129968  [input_ids, attention_mask]  \n",
              "129969  [input_ids, attention_mask]  \n",
              "129970  [input_ids, attention_mask]  \n",
              "\n",
              "[129971 rows x 16 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b7915f74-e560-4486-bf61-136b099dd584\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>country</th>\n",
              "      <th>description</th>\n",
              "      <th>designation</th>\n",
              "      <th>points</th>\n",
              "      <th>price</th>\n",
              "      <th>province</th>\n",
              "      <th>region_1</th>\n",
              "      <th>region_2</th>\n",
              "      <th>taster_name</th>\n",
              "      <th>taster_twitter_handle</th>\n",
              "      <th>title</th>\n",
              "      <th>variety</th>\n",
              "      <th>winery</th>\n",
              "      <th>processed_text</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Italy</td>\n",
              "      <td>Aromas include tropical fruit, broom, brimston...</td>\n",
              "      <td>Vulkà Bianco</td>\n",
              "      <td>87</td>\n",
              "      <td></td>\n",
              "      <td>Sicily &amp; Sardinia</td>\n",
              "      <td>Etna</td>\n",
              "      <td></td>\n",
              "      <td>Kerin O’Keefe</td>\n",
              "      <td>@kerinokeefe</td>\n",
              "      <td>Nicosia 2013 Vulkà Bianco  (Etna)</td>\n",
              "      <td>White Blend</td>\n",
              "      <td>Nicosia</td>\n",
              "      <td>wine review : Italy : Sicily &amp; Sardinia : Whit...</td>\n",
              "      <td>[input_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Portugal</td>\n",
              "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
              "      <td>Avidagos</td>\n",
              "      <td>87</td>\n",
              "      <td>15.0</td>\n",
              "      <td>Douro</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Roger Voss</td>\n",
              "      <td>@vossroger</td>\n",
              "      <td>Quinta dos Avidagos 2011 Avidagos Red (Douro)</td>\n",
              "      <td>Portuguese Red</td>\n",
              "      <td>Quinta dos Avidagos</td>\n",
              "      <td>wine review : Portugal : Douro : Portuguese Re...</td>\n",
              "      <td>[input_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>US</td>\n",
              "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
              "      <td></td>\n",
              "      <td>87</td>\n",
              "      <td>14.0</td>\n",
              "      <td>Oregon</td>\n",
              "      <td>Willamette Valley</td>\n",
              "      <td>Willamette Valley</td>\n",
              "      <td>Paul Gregutt</td>\n",
              "      <td>@paulgwine</td>\n",
              "      <td>Rainstorm 2013 Pinot Gris (Willamette Valley)</td>\n",
              "      <td>Pinot Gris</td>\n",
              "      <td>Rainstorm</td>\n",
              "      <td>wine review : US : Oregon : Pinot Gris : Tart ...</td>\n",
              "      <td>[input_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>US</td>\n",
              "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
              "      <td>Reserve Late Harvest</td>\n",
              "      <td>87</td>\n",
              "      <td>13.0</td>\n",
              "      <td>Michigan</td>\n",
              "      <td>Lake Michigan Shore</td>\n",
              "      <td></td>\n",
              "      <td>Alexander Peartree</td>\n",
              "      <td></td>\n",
              "      <td>St. Julian 2013 Reserve Late Harvest Riesling ...</td>\n",
              "      <td>Riesling</td>\n",
              "      <td>St. Julian</td>\n",
              "      <td>wine review : US : Michigan : Riesling : Pinea...</td>\n",
              "      <td>[input_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>US</td>\n",
              "      <td>Much like the regular bottling from 2012, this...</td>\n",
              "      <td>Vintner's Reserve Wild Child Block</td>\n",
              "      <td>87</td>\n",
              "      <td>65.0</td>\n",
              "      <td>Oregon</td>\n",
              "      <td>Willamette Valley</td>\n",
              "      <td>Willamette Valley</td>\n",
              "      <td>Paul Gregutt</td>\n",
              "      <td>@paulgwine</td>\n",
              "      <td>Sweet Cheeks 2012 Vintner's Reserve Wild Child...</td>\n",
              "      <td>Pinot Noir</td>\n",
              "      <td>Sweet Cheeks</td>\n",
              "      <td>wine review : US : Oregon : Pinot Noir : Much ...</td>\n",
              "      <td>[input_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129966</th>\n",
              "      <td>129966</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Notes of honeysuckle and cantaloupe sweeten th...</td>\n",
              "      <td>Brauneberger Juffer-Sonnenuhr Spätlese</td>\n",
              "      <td>90</td>\n",
              "      <td>28.0</td>\n",
              "      <td>Mosel</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Anna Lee C. Iijima</td>\n",
              "      <td></td>\n",
              "      <td>Dr. H. Thanisch (Erben Müller-Burggraef) 2013 ...</td>\n",
              "      <td>Riesling</td>\n",
              "      <td>Dr. H. Thanisch (Erben Müller-Burggraef)</td>\n",
              "      <td>wine review : Germany : Mosel : Riesling : Not...</td>\n",
              "      <td>[input_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129967</th>\n",
              "      <td>129967</td>\n",
              "      <td>US</td>\n",
              "      <td>Citation is given as much as a decade of bottl...</td>\n",
              "      <td></td>\n",
              "      <td>90</td>\n",
              "      <td>75.0</td>\n",
              "      <td>Oregon</td>\n",
              "      <td>Oregon</td>\n",
              "      <td>Oregon Other</td>\n",
              "      <td>Paul Gregutt</td>\n",
              "      <td>@paulgwine</td>\n",
              "      <td>Citation 2004 Pinot Noir (Oregon)</td>\n",
              "      <td>Pinot Noir</td>\n",
              "      <td>Citation</td>\n",
              "      <td>wine review : US : Oregon : Pinot Noir : Citat...</td>\n",
              "      <td>[input_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129968</th>\n",
              "      <td>129968</td>\n",
              "      <td>France</td>\n",
              "      <td>Well-drained gravel soil gives this wine its c...</td>\n",
              "      <td>Kritt</td>\n",
              "      <td>90</td>\n",
              "      <td>30.0</td>\n",
              "      <td>Alsace</td>\n",
              "      <td>Alsace</td>\n",
              "      <td></td>\n",
              "      <td>Roger Voss</td>\n",
              "      <td>@vossroger</td>\n",
              "      <td>Domaine Gresser 2013 Kritt Gewurztraminer (Als...</td>\n",
              "      <td>Gewürztraminer</td>\n",
              "      <td>Domaine Gresser</td>\n",
              "      <td>wine review : France : Alsace : Gewürztraminer...</td>\n",
              "      <td>[input_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129969</th>\n",
              "      <td>129969</td>\n",
              "      <td>France</td>\n",
              "      <td>A dry style of Pinot Gris, this is crisp with ...</td>\n",
              "      <td></td>\n",
              "      <td>90</td>\n",
              "      <td>32.0</td>\n",
              "      <td>Alsace</td>\n",
              "      <td>Alsace</td>\n",
              "      <td></td>\n",
              "      <td>Roger Voss</td>\n",
              "      <td>@vossroger</td>\n",
              "      <td>Domaine Marcel Deiss 2012 Pinot Gris (Alsace)</td>\n",
              "      <td>Pinot Gris</td>\n",
              "      <td>Domaine Marcel Deiss</td>\n",
              "      <td>wine review : France : Alsace : Pinot Gris : A...</td>\n",
              "      <td>[input_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129970</th>\n",
              "      <td>129970</td>\n",
              "      <td>France</td>\n",
              "      <td>Big, rich and off-dry, this is powered by inte...</td>\n",
              "      <td>Lieu-dit Harth Cuvée Caroline</td>\n",
              "      <td>90</td>\n",
              "      <td>21.0</td>\n",
              "      <td>Alsace</td>\n",
              "      <td>Alsace</td>\n",
              "      <td></td>\n",
              "      <td>Roger Voss</td>\n",
              "      <td>@vossroger</td>\n",
              "      <td>Domaine Schoffit 2012 Lieu-dit Harth Cuvée Car...</td>\n",
              "      <td>Gewürztraminer</td>\n",
              "      <td>Domaine Schoffit</td>\n",
              "      <td>wine review : France : Alsace : Gewürztraminer...</td>\n",
              "      <td>[input_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>129971 rows × 16 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b7915f74-e560-4486-bf61-136b099dd584')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b7915f74-e560-4486-bf61-136b099dd584 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b7915f74-e560-4486-bf61-136b099dd584');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-821cc0ba-9044-4b19-8ad7-90dcde96f9bc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-821cc0ba-9044-4b19-8ad7-90dcde96f9bc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-821cc0ba-9044-4b19-8ad7-90dcde96f9bc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT"
      ],
      "metadata": {
        "id": "YjPMckqLgbAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class GPTDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_ids = torch.tensor(self.data.iloc[idx][\"tokens\"][\"input_ids\"], dtype=torch.long)\n",
        "        return {\"input_ids\": input_ids}\n",
        "\n",
        "class GPT2Block(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.attention = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout)\n",
        "        self.norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.norm2 = nn.LayerNorm(embed_dim)\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(embed_dim, ff_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(ff_dim, embed_dim)\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, attn_mask=None):\n",
        "        attn_output, _ = self.attention(x, x, x, attn_mask=attn_mask, need_weights=False)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "        ffn_output = self.ffn(x)\n",
        "        x = self.norm2(x + self.dropout(ffn_output))\n",
        "        return x\n",
        "\n",
        "class CustomGPT(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_heads, num_layers, ff_dim, max_len, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.token_embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.position_embedding = nn.Embedding(max_len, embed_dim)\n",
        "        self.layers = nn.ModuleList([\n",
        "            GPT2Block(embed_dim, num_heads, ff_dim, dropout) for _ in range(num_layers)\n",
        "        ])\n",
        "        self.ln_f = nn.LayerNorm(embed_dim)\n",
        "        self.head = nn.Linear(embed_dim, vocab_size, bias=False)\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        # Input shape: (batch_size, seq_len)\n",
        "        batch_size, seq_len = input_ids.size()\n",
        "\n",
        "        # Create position ids and embeddings\n",
        "        positions = torch.arange(seq_len, device=input_ids.device).unsqueeze(0).expand(batch_size, seq_len)\n",
        "        token_embeddings = self.token_embedding(input_ids)  # (batch_size, seq_len, embed_dim)\n",
        "        position_embeddings = self.position_embedding(positions)  # (batch_size, seq_len, embed_dim)\n",
        "\n",
        "        # Combine token and position embeddings\n",
        "        x = token_embeddings + position_embeddings\n",
        "\n",
        "        # Transpose for MultiheadAttention: (seq_len, batch_size, embed_dim)\n",
        "        x = x.transpose(0, 1)\n",
        "\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "\n",
        "        # Transpose back to (batch_size, seq_len, embed_dim)\n",
        "        x = x.transpose(0, 1)\n",
        "\n",
        "        x = self.ln_f(x)  # Layer norm\n",
        "        logits = self.head(x)  # Output logits\n",
        "        return logits\n",
        "\n",
        "# Create the GPT class\n",
        "class GPTTrainer:\n",
        "    def __init__(self, vocab_size, embed_dim=256, num_heads=8, num_layers=8, ff_dim=1024, max_len=512, dropout=0.1):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = CustomGPT(vocab_size, embed_dim, num_heads, num_layers, ff_dim, max_len, dropout).to(self.device)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=5e-4)\n",
        "\n",
        "    def train(self, train_loader, epochs=3):\n",
        "        self.model.train()\n",
        "        for epoch in range(epochs):\n",
        "            epoch_loss = 0\n",
        "            for batch in train_loader:\n",
        "                input_ids = batch[\"input_ids\"].to(self.device)\n",
        "                labels = input_ids.clone()\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                logits = self.model(input_ids)\n",
        "                loss = self.criterion(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "            print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss / len(train_loader)}\")\n",
        "\n",
        "    def save_model(self, path):\n",
        "        torch.save(self.model.state_dict(), path)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    input_ids = [item[\"input_ids\"].squeeze(1) if len(item[\"input_ids\"].shape) > 1 else item[\"input_ids\"] for item in batch]\n",
        "    padded_input_ids = pad_sequence(input_ids, batch_first=True, padding_value=0)  # 0 is the padding token ID\n",
        "    return {\"input_ids\": padded_input_ids}"
      ],
      "metadata": {
        "id": "YDux1hvFfHt_"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = processor.get_data_for_training()\n",
        "dataset = GPTDataset(train_data)\n",
        "train_loader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "gpt_trainer = GPTTrainer(vocab_size=len(processor.tokenizer))\n",
        "gpt_trainer.train(train_loader, epochs=5)\n",
        "gpt_trainer.save_model(\"custom_gpt_model.pth\")"
      ],
      "metadata": {
        "id": "K2oY6JrlggU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VgiHHCwkgtl9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "N0RE0-AVAkPp"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}